
"""Служебные функции для управления геометрией камеры.

* Где возможно эти функции работают на последних 1 или 2 измерениях своих входов и будут работать независимо
от того, как много предыдущих измерений уже внесено. Где имеет смысл функции поддерживают передачу формы (shape),
прешедствующую фиксации

* Позы камеры представлены как 3x4 матрицы ( 3x3 матрица поворота (rotation)
  и 3-кординантный вектор переноса):
    [[ r r r tx ]
     [ r r r ty ]
     [ r r r tz ]]
  Матрица отражает позицию в мире (world-space) в позицию относительно позиции камеры
  (В позиции камеры Z указывает в экран а Y  вниз.
  Функции для манипулирования подобной матрицей начинаются с "mat34_".

* Внутрение характеристики камеры представлены в виде 4 мерного тензора. Эти элементы это
  fx, fy (фокусное расстояние) и cx, cy (главная точка (principal point)). Они
  независимы от размера изображения, они представленны (expressed) как если бы изображение
  обрабатывалось (runs) от (0,0) к (1,1). Обычно cx == cy == 0.5, и для поля зрения 90 градусов fx == 0.5.

* Точки (points) (2D или 3D) представленны с использованием последней оси тензора.
  Набор 3D будет предствлен как [N, 3].

* Мы используем координаты текстур для представления точек на изображении. Они идут от (0,0)
  в верхнем левом углу до (1,1) в нижнем правом. Работать с координатами удобнее чем считать пиксели
  так как они независимы от разрешения изображения
"""
import tensorflow as tf


def broadcast_to_match(a, b, ignore_axes=0):
  """Возвращает (a', b') которые транслируются чтобы иметь одну форму (shape).

  Предположем мы хотим применить операцию к тензорам но она не поддерживает передачу.
  Например у нас есть тензор такой формы (shape):
    a    [5, 1, 3, 4]
    b [2, 1, 8, 4, 2]
  Представив два последних измерения как матрицы, мы хотим умножить а на b чтобы получить тензор
  [2, 5, 8, 3, 2] из (2x3) матриц. Но, tf.matmul не поддерживает операцию так как размеры не совпадают. Вызов
  tf.matmul(a, b) напрямую вызовет ошибку.

  Однако размеры совпадают при трансляции, поэтому умножение можно сделать так:
    a, b = broadcast_to_match(a, b, ignore_axes=2)
    c = tf.matmul(a, b)
  Параметр ignore_axes указывает игнорировать два последних измерения a
  и b и просто сделать чтобы все остальное совпало.

  Аргументы:
    a: Любая форма (shape)
    b: Любая форма (shape)
    ignore_axes: Если есть, трансляция не булет применена к последним осям.
    Например если надо вызвать tf.matmul(a, b) на результате то установи ignore_axes=2
    так как tf.matmul работает на последних 2 осях, только остальные надо сравнить.
    Чтобы проигнорировать другое количество осей для входных данных
    a и b, передать пару значений в ignore_axes.

  Возвращает:
    a', b': Идентичны исходным, но изменены (tiled) чтобы совпадала форма.
  """
  a = tf.convert_to_tensor(a) # конвертирует в тензор
  b = tf.convert_to_tensor(b)
  a_shape = a.shape.as_list() # представляет тензор как список int или None для каждой плоскости (dimenshions)
  b_shape = b.shape.as_list()
  # Выделение части необходимой к совпаданию.
  if isinstance(ignore_axes, tuple) or isinstance(ignore_axes, list): # является ли ignore_axes кортежем (tuple) или списком
    ignore_a = ignore_axes[0]
    ignore_b = ignore_axes[1]
  else:
    ignore_a = ignore_axes
    ignore_b = ignore_axes
  if ignore_a:
    a_shape = a_shape[:-ignore_a]
  if ignore_b:
    b_shape = b_shape[:-ignore_b]
  if a_shape == b_shape:
    return (a, b)
  # Дополнительно поддерживает трансляцию, поэтому добавляется тензор нудей.
  za = tf.zeros(a_shape + [1] * ignore_b, dtype=b.dtype) # Создает тензор со всеми элементами, записанными как ноль
  zb = tf.zeros(b_shape + [1] * ignore_a, dtype=a.dtype)
  a += zb
  b += za

  a_new_shape = a.shape.as_list()
  b_new_shape = b.shape.as_list()
  if ignore_a:
    a_new_shape = a_new_shape[:-ignore_a]
  if ignore_b:
    b_new_shape = b_new_shape[:-ignore_b]
  assert a_new_shape == b_new_shape
  return (a, b)


def mat34_to_mat44(matrix):
  """Конвертирует 3x4 матрицы в 4x4 добавляя наполнитель.

  Учитывая два последних измерения входного тензора, где m
  это матричный коэффициент а t a коэффициент для перевода,
  функция делает следующее:
       [[m, m, m, t],           [[m, m, m, t],
        [m, m, m, t],    ===>    [m, m, m, t],
        [m, m, m, t]]            [m, m, m, t],
                                 [0, 0, 0, 1]]

  Аргументы:
    matrix: [..., 3, 4] матрица

  Возвращает:
    A [..., 4, 4] тензор с новой строкой [0, 0, 0, 1] добавленной к каждой матрице.
    Кроме этих двух данные не менеяются.
  """
  shape = matrix.shape.as_list()

  extra_dims = shape[:-2]
  filler = tf.constant([0.0, 0.0, 0.0, 1.0], # создает тензор констант из подобного тензору объекта (тут массив)
                       shape=len(extra_dims) * [1] + [1, 4]) # Объединяет список значений ([0.0, 0.0, 0.0, 1.0]) тензоров вдоль оси (shape=len(extra_dims) * [1] + [1, 4]) измерения
  filler = tf.tile(filler, extra_dims + [1, 1]) # создает новый тензор реплицируя или копируя ввод (filler) множество (extra_dims + [1, 1]) раз
  return tf.concat([matrix, filler], axis=-2) # Объединяет тензоры вдоль одномй плоскости


def mat34_transform(m, v):
  """Преобразование набора 3D точек с помощью матрицы поз 3x4.

  Аргументы:
    m: [..., 3, 4] матрица
    v: [..., N, 3] набор из N 3d точек.

  Возвращает:
    Измененные точки mv. Преобразование вычисляется так, как если бы мы добавили дополнительный коэффициент
    1.0 к каждой точке, выполнили матричное умножение и снова удалили коэффициент. Части (shape) обозначенные "...",
    должны совпадать либо напрямую, либо через трансляцию

  Ошибки:
    ValueError: если входы неправильной формы (shape).
  """
  (m, v) = broadcast_to_match(m, v, ignore_axes=2)
  rotation = m[Ellipsis, :3]

  translation = m[Ellipsis, 3]
  translation = translation[Ellipsis, tf.newaxis, :]  # Теперь матрица имеют форму (shape) [..., 1, 3].
  # Точки хранятся как (N * 3) а не (3 * N), так что вместо транспонирования лучше сделать обратное умножение
  return tf.matmul(v, rotation, transpose_b=True) + translation # умножает матрицу a на b получая a*b, transpose_b=True
                                                                # значит что b транспонирована перед умножением


def mat34_product(a, b):
  """Возвращает продукт a и b, 3x4 матрицы. Пояснения ниже

  Аргументы:
    a: [..., 3, 4] матриц
    b: [..., 3, 4] матриц

  Возвращает:
    Продукт ab. Продукт вычисляется как добавление дополнительной строки
    [0, 0, 0, 1] к каждой матрице, их перемножение, а затем удаление дополнительной строки.
    Формы (shape) a и b должны совпадать, либо напрямую либо через передачу.

  Ошибки:
    ValueError: если a или b не матрицы 3x4.
  """

  (a, b) = broadcast_to_match(a, b, ignore_axes=2)
  # Отделить переводящую (translation) часть от остальных
  a33, a_translate = tf.split(a, [3, 1], axis=-1) # делит значение (тут a) на список подтензоров
  b33, b_translate = tf.split(b, [3, 1], axis=-1) # axis=-1 это плоскость вдоль которой идет деление
  # Вычислить части продукта
  ab33 = tf.matmul(a33, b33)
  ab_translate = a_translate + tf.matmul(a33, b_translate)
  # Соединить их
  return tf.concat([ab33, ab_translate], axis=-1)


def mat34_pose_inverse(matrix):
  """Инвертирование матрицы 3x4.

  Аргументы:
    matrix: [..., 3, 4] матрицы где [..., 3, 3] матрицы вращения

  Возвращает:
    Инвертированная матрица, той же вормы как и входная. Вычисляется как если
    мы добавляем дополнительную строку [0, 0, 0, 1], инвертируем
    и удаляем строку.
  """
  rest, translation = tf.split(matrix, [3, 1], axis=-1)
  inverse = tf.linalg.matrix_transpose(rest) # транспонирует 2 последние плоскости
  inverse_translation = -tf.matmul(inverse, translation)
  return tf.concat([inverse, inverse_translation], axis=-1)


def homogenize(coords):
  """Convert (x, y) to (x, y, 1), or (x, y, z) to (x, y, z, 1)."""
  ones = tf.ones_like(coords[Ellipsis, :1]) # создает тензор из единиц такой же формы что и поданный на вход функции
  return tf.concat([coords, ones], axis=-1)


def texture_to_camera_coordinates(coords, intrinsics):
  """Преобразовывает координаты текстур к x,y,1 к координатам относительно камеры.

  Args:
    coords: [..., 2] координаты текстур
    intrinsics: [..., 4] (независимый от разрешения) параметры (intrinsics) камеры. Последнее измерение (fx, fy, cx, cy).

  Returns:
    [..., 3] координаты, преобразованные путем уменьшения размера изображения
    применяя инверсию внутренних параметров. z-координата везде 1.
  """
  # Сдвиг к оптическому центру и деление на фокусное расстояние.
  # (Это поэлементные операции над координатами x и y.)
  focal_length, optical_center = tf.split(intrinsics, [2, 2], axis=-1)
  xy_coords = (coords - optical_center) / focal_length
  return homogenize(xy_coords)
